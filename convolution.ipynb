{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network\n",
    "\n",
    "**Images are represented as  3-dimensional tensors, of dimensions height × width × 3, where the last dimension captures the color channels.**\n",
    "\n",
    "**Convolutional neural networks have the ability to filter local regions of images to recognize patterns.**\n",
    "\n",
    "• Training is usually done using Stochastic Gradient Decenter\n",
    "• Use cross entropy loss for classification and MSE for regression\n",
    "• Batch normalization is applied to make training easier\n",
    "• Convolution layers exploit local patterns in images\n",
    "\n",
    "if the data from an image was simply vectorized, it would be one long many-dimensional vector.  There'd be no spatial relationship among dimensions.  Filtering indentifies local patterns. \n",
    "\n",
    "images have a huge number of dimensions (i.e. each image is actuall three images: red, green, blue. In 1000x1000 px image, thats actually 3 million px)\n",
    "*fitting that that many parameters would take a ton of training data*\n",
    "*red, green, blue are \"channels\"*\n",
    "\n",
    "Convolutional Neural Networks are good for image data and time-series data\n",
    "\n",
    "![convolution.jpg](convolution.jpg)\n",
    "\n",
    "translation invariant == Translation invariance is when a system produces the same output regardless of how its input is translated. For example, a face-detector might report \"FACE FOUND\" for all three images in the top row. \n",
    "\n",
    "In Euclidean geometry, translation is a geometric transformation that means moving an image or every point in space the same distance in the same direction\n",
    "\n",
    "In computer vision, translation invariance is a result of the pooling operation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering\n",
    "\n",
    "convolution: passing a filter (with learned kernel) over the image to find patterns.\n",
    "\n",
    "These filters are learned through training and optimized during back propagation. \n",
    "\n",
    "the convolved image == feature map\n",
    "\n",
    "feature map is the result of the filtering operation for all pixels\n",
    "\n",
    "Get many feature maps per layer, use the output feature maps as inputs to the next layer\n",
    "\n",
    "Different filters for each image map\n",
    "\n",
    "filters are applied to images through the convolution operation\n",
    "\n",
    "Stride is the amount by which the filter is moved by as it passes over the image. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling\n",
    "\n",
    "The pooling layer essentially introduces translation invariance into Convolutional Neural Networks\n",
    "\n",
    "Pooling layers = shrink (blur) the feature map\n",
    "\n",
    "One way: 2 x 2 filter across the feature map, take only the max value of the 2 x 2 square, so 4 values become one.  \n",
    "\n",
    "identifies patterns (cat eyes, cat ears, cat mouth -- for examples) without respect to where they are located in the feature map\n",
    "\n",
    "Pooling introduces translation invariance by conveying what patterns are apparent in the image, without conveying where they are exactly.\n",
    "\n",
    "Two common pooling methods are max pooling and mean pooling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Normalization\n",
    "\n",
    "objectives: \n",
    "- Normalizing all points to have 0 mean and standard deviation 1.\n",
    "- Learn an offset and a scalar\n",
    "- Calculate the mean and standard deviation for all the points in the minibatch.\n",
    "\n",
    "Normalize input features\n",
    "\n",
    "Subtract the mean across the training data set\n",
    "\n",
    "for deeper layers, you take a minibatch: \n",
    "\n",
    "Get the mean of the minibatch\n",
    "\n",
    "Get the standard deviation (variance in minibatch / variance)\n",
    "\n",
    "output: offset, multiplicative scalar\n",
    "\n",
    "Divide by the variance\n",
    "\n",
    "- A batch normalization layer of a neural network computes the mean and standard deviation of each pixel of the activations in this layer across the entire minibatch. \n",
    "- This information is then used to normalize the activations  \n",
    "    - subtract the mean and divide by the standard deviation. \n",
    "- The result is much more stable training and improved tolerance toward large learning rates.\n",
    "\n",
    "pseudocode :\n",
    "\n",
    "typical normalization: \n",
    "\n",
    "input = (input - mean) / standard deviation\n",
    "\n",
    "batch normalization: \n",
    "\n",
    "activations = scaling parameter * ((activations - mean / square root of  variance in mini-batch for dimension i + little e)) + beta\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual and Dense Networks \n",
    "\n",
    "Features extracted from convolutional filters can be useful at various stages of the neural network\n",
    "\n",
    "Residual networks prevent these features from being lost\n",
    "\n",
    "residual network is the output of the layer plus the input \n",
    "\n",
    "DenseNet\n",
    "\n",
    "adds features from the previous layer as input to the next layer and ALL subsequent layers\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pytorch\n",
    "\n",
    "1.  In Pytorch, to create a model, we need to create a model class that overloads nn.Module and implement the forward() function that performs forward propagation. (write the code)\n",
    "2.  Define a loss function (pytorch has libraries)\n",
    "3.  Define an optimizer (pytorch has libraries)\n",
    "4.  Train the network (write the code)\n",
    "5.  Evaluate the network (write the code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tensorflow\n",
    "\n",
    "TensorFlow does 1 - 4. \n",
    "\n",
    "1. Creating a model\n",
    "2. Define a loss function\n",
    "3. Define an optimizer\n",
    "4. Training the Network\n",
    "5. Evaluate the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

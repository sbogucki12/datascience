{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-linear functions\n",
    "\n",
    "\n",
    "- multi-layer Perceptron == artificial neural network instead of learning one function, it learns many linear functions \n",
    "- linear function == w Transpose x (this particular function goes through the origin) \n",
    "- adding offset b shifts the line from the origin, so w Transpose x + b\n",
    "- if we want to add angles to the line, we use a hinge function max(w Transpose x +b, 0) == hinge function\n",
    "- Multiply the function by a scalar and add a constant to hinge the line downward (negative) u \\* max(w Transpose x +b, 0) + c\n",
    "- Keep adding on hinge functions with different scalars to get the desired curve. \n",
    "- so a neural network is the function h(x), which is Sum up all the hinge functions, including their scalars, take the max(w Transpose x + b, 0) + one constant\n",
    "- In matrix format, W, b and the scalar are all now vectors scalar Transpose max(W + b, 0) plus the constant \n",
    "- Use Stochastic Gradient Descent to turn the weights, scalar, and offset into vectors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks\n",
    "\n",
    "\n",
    "\n",
    "- Add to the h(x) a sigma sigma os max(a, 0) \n",
    "- The **non-deep learning** way to get better apprixmation of the nonlinear function is to add more and more dimensions\n",
    "- The deep learning way to get better approximation of the nonlinear function is add more and more hidden layers. \n",
    "- Hidden layers contain neurons that correspond to hinge functions\n",
    "- The layers create \"kinks\" in the line at an exponential rate. Each layer can have four hidden neurons each, but they add 4, 16, 32, 64... kinks. So if we want to have a million kinks, we would just need 20 layers of four hidden neurons each, so that's just 80 hidden neurons.\n",
    "- Neural networks use piecewise linear functions to approximate decision boundaries. \n",
    "- It is possible to approximate any linear or nonlinear function. \n",
    "- Using fewer parameters allows for better generalizations.\n",
    "- To make networks more powerful, you either increase the number of linear functions or add more layers. \n",
    "- Adding more layers: \n",
    "  - h(x)=Wlσ(Wl−1σ(⋯W2σ(W1x)⋯))\n",
    "  - The first layer in the network learns piecewise linear functions to approximate nonlinear boundaries. It does this in two steps: \n",
    "  - W1x: This learns M linear functions. \n",
    "  - σ(W1x): This sets every negative value equal to 0, creating the kinks.\n",
    "  - Every subsequent layer in the network essentially does two things: \n",
    "  - Combines linear combinations of the functions of the previous layer and aggregates them together. This is represented by Wkσ(Wk−1)\n",
    "  - Set every negative value from Wkσ(Wk−1) to equal 0. This is represented by σ(Wkσ(Wk−1))\n",
    "- Wl == W is the accumulating linear equations and l is the number of linear equations\n",
    "\n",
    "The last layer determines the type of output of the neural network and is chosen to fit the use case. For example, we can use the softmax function for a classification problem or the identity function (i.e., just outputting the input) for a regression problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transition Functions\n",
    "\n",
    "the hinge function that we have been using (that creates the \"kink\" by setting a linear function to zero) is called a REctified Linear Unit (ReLU)\n",
    "ReLU mostly replaced the sigmoid and tanh transition functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Entropy Loss Function\n",
    "\n",
    "Neural networks, like any other model, require a loss function to optimize\n",
    "the loss functions comes in the last layer\n",
    "softmax transition function turns outputs into probabilities (this is different than ReLU)\n",
    "the probabilities work like this: \n",
    "\n",
    "Say, the input is a dog, and three outputs are 10% cat, 20% dog, 70% cow, then we want to train the model to decrease probability of cat and cow and increase dog. \n",
    "We do this by maximizing the probability of the correct label for every single input\n",
    "To deal with the products of the probabilities, take the log.  And since we want to minimize not mazimize, we make the log negative.   \n",
    "\n",
    "Neural networks can be used for regression and classification.\n",
    "The output of a regression network is a real number or vector of real numbers. \n",
    "The output of the neural network for classification is a normalized probability vector.\n",
    "\n",
    "One dimensional regression has a one dimensional output (though, we can do regressions on more dimensions)\n",
    "Classification problems output \"belief vectors\" (also known as logits)\n",
    "Every element in the belief vector corresponds to the model's belief that the input example belongs to a certain class. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Propagation\n",
    "\n",
    "Putting the input into the network, training, and getting probabilities as outputs\n",
    "each layer takes the output of the previous layer and does two operations: \n",
    "multiple the output by a matrix, call that vector A\n",
    "Multiply vector A by transition function, call that Q\n",
    "Q is the output of the current layer and the input for the next layer\n",
    "(**note**: A and Q here are A and Z in exercises)\n",
    "(Also, we add a constant to the output of the layers)\n",
    "![image.png](fwdpass_text.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back Propagation\n",
    "\n",
    "Updating our weights to minimize the loss function \n",
    "Use gradient descent\n",
    "compute the graident of the loss function with respect to every matrix\n",
    "Gradient step over and over\n",
    "back propagation == start with the output and propagate the gradient back through the neural network to the beginning, updating the weights along the way.\n",
    "to do this, you compute the gradient for each Matrix which is this layer's matrix multiplied by the output of the previous layer\n",
    "We train the model using gradient descent, so we update Wl with ∂L/∂Wl\n",
    "to calculate ∂L/∂Wl, we use the chain rule: ∂L/∂Wl = ∂L/∂al ⊙ ∂al/∂Wl and ∂L/∂al−1 = ∂L/∂al ⊙ ∂al/∂al−1\n",
    "![image.png](backpass_text.png)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent (SGD) \n",
    "\n",
    "The Stochastic approach is to take a minibatch of data and update the weights based on it\n",
    "Gradient descent is the sum of all losses with respect to the weights. \n",
    "\n",
    " the gradient of the overall loss, L, is the average of the gradients of the losses computed for each individual data point ( x, y) in the dataset\n",
    "\n",
    " computing the average direction in which the loss function increases the most, across all individual data points."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

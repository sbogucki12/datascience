{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance, Bias, Noise\n",
    "\n",
    "These three terms, and only these three terms, contribute to your error.\n",
    "\n",
    "In the example of regression analysis to predict housing prices, there could be an unaccounted-for feature that distorts the label. \n",
    "\n",
    "So, while we may have features for \"square footage\", \"crime rate\", \"number of bathrooms\", etc, there could be a feature like \"did a celebrity live there?\" that could be unaccounted for that makes the label different than the expected label.   \n",
    "\n",
    "### Minimizing error\n",
    "\n",
    "Train a classifier D on some training data set, and then draw a new data point x with a label y, how far off would we be; what would be the expected test error of this algorithm? \n",
    "\n",
    "That's all you want to minimize, ultimately, if you design a new algorithm.\n",
    "\n",
    "Total Error = *Bias^2 + Variance + Noise*\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise\n",
    "\n",
    "Noise is the expected difference between the label of a data point and its expected label\n",
    "\n",
    "Typically don't address noise via the machine learning algorithm, you minimize noise by cleaning the data, adding features, or other data preparation steps. \n",
    "\n",
    "How large is the data-intrinsic noise? This error measures ambiguity due to your data distribution and feature representation. You can never reduce it algorithmically; it is an inherent aspect of the data. You might, however, be able to add more features that capture this seemingly random variability.\n",
    "\n",
    "To formally compute noise: \n",
    "\n",
    "Compute the noise by just putting the squared difference of the actual label and the expected label. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance\n",
    "\n",
    "Captures how much your hypothesis function changes if you train on a different training set. How \"overspecialized\" is your hypothesis to a particular training set? If we have the best possible model for our training data, how far off are we from the average hypothesis?\n",
    "\n",
    "Variance refers to the sensitivity of the model to fluctuations in the training data. A model with high variance tends to overfit the data, meaning it learns the training data too well and struggles to generalize to new, unseen data.\n",
    "\n",
    "How much do our classifiers vary if we train them on different data sets?\n",
    "\n",
    "How different is that prediction from the average prediction? Or the expected prediction we would get if we had infinite amount of data?\n",
    "\n",
    "The variance is the error that you get because you trained on one specific data set and not infinite amounts.\n",
    "\n",
    "When training on different data sets, overfit classifiers are more likely to have a greater spread.\n",
    "\n",
    "When training on different data sets, you can get classifiers that vary greatly from each other.\n",
    "\n",
    "​​​​​​The average classifier, h-bar(x), returns the average prediction of classifiers trained on all possible data sets.\n",
    "\n",
    "Training error is much lower than test error.\n",
    "\n",
    "To lower variance:\n",
    "\n",
    "* Add more training data, if possible. \n",
    "\n",
    "* Reduce model complexity \n",
    "\n",
    "* Bagging\n",
    "\n",
    "To formally compute variance: \n",
    "\n",
    "For each one of these hundred data sets, you train a different regression tree, and then you compute the average prediction, and you compute the average squared difference from the prediction across all these hundred different trees for every single data point; that's the variance of your classifier\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias \n",
    "\n",
    "What is the inherent error that you obtain from your hypothesis function even with infinite training data, i.e., from your average hypothesis? This is due to your hypothesis function being \"biased\" to a particular kind of solution (e.g. linear classifier).  In other words, bias is inherent to your model.\n",
    "\n",
    "Bias refers to the error introduced by approximating a real-world problem with a simplified model. A model with high bias tends to underfit the data, meaning it oversimplifies the underlying patterns and fails to capture the complexities in the data. \n",
    "\n",
    "Training error is higher than epsilon (the threshold for allowed error)\n",
    "\n",
    "The bias is the prediction of the average classifier minus the average label squared.\n",
    "\n",
    "Bias is error that you would get even if you had unlimited data (because the classifier is introducing the error)\n",
    "\n",
    "To lower bias: \n",
    "\n",
    "* Increase features\n",
    "\n",
    "* Add depth, decrease regularization, make linear non-linear\n",
    "\n",
    "* Boosting \n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Label\n",
    "\n",
    "#### Y-bar\n",
    "\n",
    "First, let us consider that for any given input x there might not exist a unique label y. For example, if your vector x describes features of a house (e.g. number of bedrooms, square footage) and the label y its price, you could imagine two houses with identical descriptions selling for different prices. So, for any given feature vector x, there is a distribution over possible labels."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
